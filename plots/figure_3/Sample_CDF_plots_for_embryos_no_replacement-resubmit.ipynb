{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np; np.random.seed(0)\n",
    "import seaborn as sns;\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.stats\n",
    "import math\n",
    "from ete3 import Tree\n",
    "%matplotlib inline  \n",
    "pylab.rcParams['figure.figsize'] = 15, 15  # our default image size\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load up the allReads file into an array of events\n",
    "class Event:\n",
    "    def __init__(self,line,sample):\n",
    "        self.sample = sample\n",
    "        \n",
    "        sp = line.split(\"\\t\")\n",
    "        self.hmid = \"_\".join([x if x != \"UNKNOWN\" else \"NONE\" for x in sp[0].split(\"_\")])\n",
    "        self.array = int(sp[1])\n",
    "        self.count = int(sp[2])\n",
    "        self.proportion = float(sp[3])\n",
    "        \n",
    "def load_sample(sample_file, sample):\n",
    "    header = sample_file.readline().strip(\"\\n\").split(\"\\t\")\n",
    "    events = []\n",
    "    \n",
    "    for line in sample_file:\n",
    "        events.append(Event(line,sample))\n",
    "    return events\n",
    "    \n",
    "# the two sample tables to load\n",
    "old_dir = \"/mount/vol10/CRISPR.lineage/nobackup/2016_05_04_Early_embryo_target_6_and_7/data/\"\n",
    "new_dir = \"/mount/vol10/CRISPR.lineage/nobackup/2016_05_04_embryo_rerun/data/\"\n",
    "\n",
    "old_samples = open(old_dir + \"/crispr_tearsheet.txt\")\n",
    "new_samples = open(new_dir + \"/crispr_tearsheet.txt\")\n",
    "\n",
    "old_samples.readline()\n",
    "new_samples.readline()\n",
    "sample_names = []\n",
    "sample_to_events = {}\n",
    "\n",
    "for line in new_samples:\n",
    "    sp = line.split(\"\\t\")\n",
    "    filename = new_dir + \"/pipeline_output/\" + sp[0] + \"/\" + sp[0] + \".allReadCounts\"\n",
    "    if os.path.exists(filename):\n",
    "        sample_hmids = load_sample(open(filename),sp[0])\n",
    "        sample_names.append(sp[0])\n",
    "        sample_to_events[sp[0]] = sample_hmids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampling_repeats = 500\n",
    "\n",
    "# for a sample, pull N HMIDs, ask if we've seen it before, \n",
    "# if so the Nth array value gets a 0 or 1.  Average over simulations\n",
    "def simulate_sample(sample):\n",
    "    \n",
    "    # make a linear version of the HMIDs from the count data\n",
    "    this_sample = sample_to_events[sample]\n",
    "    hmid_vector = []\n",
    "    for hmid in this_sample:\n",
    "        for i in range(0,hmid.count):\n",
    "            hmid_vector.append(hmid)\n",
    "    print sample + \" of length \" + str(len(hmid_vector))\n",
    "    # now sample from that linear array, and ask if we've seen the HMID already\n",
    "    unique_count = np.zeros((len(hmid_vector),sampling_repeats))\n",
    "    \n",
    "    for repeat in range(0,sampling_repeats):\n",
    "        seen_HMIDs = {}\n",
    "        # rand_HMIDs = np.random.randint(0, len(hmid_vector), size=sampled_cells)\n",
    "        rand_HMIDs = np.random.choice(len(hmid_vector),size=len(hmid_vector),replace=False)\n",
    "        for index in range(0,len(hmid_vector)):\n",
    "            hmid = hmid_vector[rand_HMIDs[index]]\n",
    "            new_val = 1\n",
    "            if hmid.hmid in seen_HMIDs:\n",
    "                new_val = 0\n",
    "            unique_count[index,repeat] = unique_count[index,repeat] + new_val\n",
    "            seen_HMIDs[hmid.hmid] = True\n",
    "    \n",
    "    return unique_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def results_to_eCDF_vector_and_sd(input_matrix):\n",
    "    sum_val = 0.0\n",
    "    num_cols = input_matrix.shape[1]\n",
    "    \n",
    "    return_matrix = np.zeros((len(input_matrix),2))\n",
    "    for i in range(0,len(input_matrix)):\n",
    "        mean_val = np.mean(input_matrix[i,].flatten())\n",
    "        return_matrix[i,0] = mean_val + sum_val\n",
    "        sum_val += mean_val\n",
    "        \n",
    "        sub_matrix = np.sum(input_matrix[0:i,],axis=0)\n",
    "        return_matrix[i,1] = np.std(sub_matrix)\n",
    "    return return_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_output(axis):\n",
    "    return (str(axis[0,]) + \"\\t\" + str(axis[1,]))\n",
    "\n",
    "def to_output_file(sample,matrix,output_file):\n",
    "    concentration = \"1X\"\n",
    "    hours = \"4.3H\"\n",
    "    \n",
    "    if \"0.3x\" in sample:\n",
    "        concentration = \"1/3X\"\n",
    "    if \"epi\" in sample:\n",
    "        hours = \"9H\"\n",
    "    if \"30hr\" in sample:\n",
    "        hours = \"30H\"\n",
    "    if \"3d\" in sample:\n",
    "        hours = \"72H\"\n",
    "    \n",
    "    for i,row in enumerate(matrix):\n",
    "        output_str = to_output(row)\n",
    "        output_file.write(sample + \"\\t\" + concentration + \"\\t\" + hours + \"\\t\" + str(i+1) + \"\\t\" + output_str + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dome_1_1x of length 1262\n",
      "Dome_3_1x of length 2036\n",
      "Dome_5_1x of length 861\n",
      "Dome_8_1x of length 1385\n",
      "Dome_10_1x of length 2258\n",
      "Dome_5_0.3x of length 2571\n",
      "Dome_6_0.3x of length 3028\n",
      "epi90_2_1x of length 4053\n",
      "epi90_5_1x of length 4014\n",
      "epi90_8_1x of length 2901\n",
      "epi90_9_1x of length 3415\n",
      "epi90_12_1x of length 6259\n",
      "epi90_1_0.3x of length 2087\n",
      "epi90_2_0.3x of length 7686\n",
      "epi90_3_0.3x of length 3239\n",
      "epi90_9_0.3x of length 8776\n",
      "epi90_10_0.3x of length 9480\n",
      "epi90_12_0.3x of length 6876\n",
      "30hr_1_1x of length 10697\n",
      "30hr_2_1x of length 6633\n",
      "30hr_3_1x of length 24023\n",
      "30hr_4_1x of length 9006\n",
      "30hr_5_1x of length 23385\n",
      "30hr_6_1x of length 15414\n",
      "30hr_1_0.3x of length 10429\n",
      "30hr_2_0.3x of length 9430\n",
      "30hr_3_0.3x of length 14059\n",
      "30hr_4_0.3x of length 14839\n",
      "30hr_5_0.3x of length 17878\n",
      "30hr_6_0.3x of length 15910\n",
      "3d_1_1x of length 25584\n",
      "3d_2_1x of length 14691\n",
      "3d_3_1x of length 17984\n",
      "3d_4_1x of length 6574\n",
      "3d_5_1x of length 9541\n",
      "3d_6_1x of length 9752\n",
      "3d_1_0.3x of length 21720\n",
      "3d_2_0.3x of length 25480\n",
      "3d_3_0.3x of length 21756\n",
      "3d_4_0.3x of length 23258\n",
      "3d_5_0.3x of length 8785\n",
      "3d_6_0.3x of length 31639\n",
      "3d_1b_1x of length 20475\n",
      "3d_1b_0.3x of length 12382\n",
      "Dome_7_0.3x of length 2137\n",
      "Dome_10_0.3x of length 2323\n"
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "# ------------------------------------------------------------------------------------------\n",
    "output_file = open(\"test_simulation_no_replace_version2.txt\",\"w\")\n",
    "output_file.write(\"sample\\tconcentration\\thours\\tindex\\tmean\\tstd\\n\")\n",
    "def simulate_samples(sample):\n",
    "    ret = simulate_sample(sample)\n",
    "    ret2 = results_to_eCDF_vector_and_sd(ret)\n",
    "    to_output_file(sample,ret2,output_file)\n",
    "\n",
    "for sample in sample_names:\n",
    "    if len(sample_to_events[sample]) > 100:\n",
    "        simulate_samples(sample)\n",
    "    \n",
    "    \n",
    "output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
